{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grandmaster = pd.read_csv('Dataset/perMinuteDataset/10min/GRANDMASTER.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chanllenger :  result\n",
      " 1    4836\n",
      "-1    4836\n",
      "Name: count, dtype: int64\n",
      "Grandmaster :  result\n",
      " 1    6365\n",
      "-1    6365\n",
      "Name: count, dtype: int64\n",
      "Master :  result\n",
      " 1    8838\n",
      "-1    8838\n",
      "Name: count, dtype: int64\n",
      "Emerald :  result\n",
      " 1    18621\n",
      "-1    18621\n",
      "Name: count, dtype: int64\n",
      "Platinum :  result\n",
      " 1    19067\n",
      "-1    19067\n",
      "Name: count, dtype: int64\n",
      "Gold :  result\n",
      " 1    11332\n",
      "-1    11332\n",
      "Name: count, dtype: int64\n",
      "Silver :  result\n",
      " 1    13167\n",
      "-1    13167\n",
      "Name: count, dtype: int64\n",
      "Bronze :  result\n",
      " 1    19057\n",
      "-1    19057\n",
      "Name: count, dtype: int64\n",
      "Iron :  result\n",
      " 1    18524\n",
      "-1    18524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "win_10_Chanllenger = pd.read_csv('Dataset/win_10/10_Chanllenger.csv')\n",
    "lose_10_Chanllenger = pd.read_csv('Dataset/lose_10/10_Chanllenger_lose.csv')\n",
    "win_10_Chanllenger_ver2 = pd.read_csv('Dataset/win_10/10_Chanllenger_ver2.csv')\n",
    "lose_10_Chanllenger_ver2 = pd.read_csv('Dataset/lose_10/10_Chanllenger_ver2_lose.csv')\n",
    "Chanllenger1 = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "Chanllenger2 = pd.concat([win_10_Chanllenger_ver2, lose_10_Chanllenger_ver2], ignore_index=True)\n",
    "Chanllenger = pd.concat([Chanllenger1, Chanllenger2], ignore_index=True)\n",
    "print('Chanllenger : ', Chanllenger['result'].value_counts())\n",
    "\n",
    "win_10_Grandmaster = pd.read_csv('Dataset/win_10/10_Grandmaster.csv')\n",
    "lose_10_Grandmaster = pd.read_csv('Dataset/lose_10/10_Grandmaster.csv')\n",
    "Grandmaster = pd.concat([win_10_Grandmaster, lose_10_Grandmaster], ignore_index=True)\n",
    "print('Grandmaster : ', Grandmaster['result'].value_counts())\n",
    "\n",
    "# win_Chanllenger = pd.read_csv('Dataset/win/Chanllenger.csv')\n",
    "# lose_Chanllenger = pd.read_csv('Dataset/lose/Chanllenger_lose.csv')\n",
    "# Chanllenger = pd.concat([win_Chanllenger, lose_Chanllenger], ignore_index=True)\n",
    "# print(Chanllenger['result'].value_counts())\n",
    "\n",
    "# win_Grandmaster = pd.read_csv('Dataset/win/Grandmaster.csv')\n",
    "# lose_Grandmaster = pd.read_csv('Dataset/lose/Grandmaster_lose.csv')\n",
    "# Grandmaster = pd.concat([win_Grandmaster, lose_Grandmaster], ignore_index=True)\n",
    "\n",
    "win_Master = pd.read_csv('Dataset/win/Master.csv')\n",
    "lose_Master = pd.read_csv('Dataset/lose/Master_lose.csv')\n",
    "Master = pd.concat([win_Master, lose_Master], ignore_index=True)\n",
    "print('Master : ', Master['result'].value_counts())\n",
    "\n",
    "win_Emerald_I = pd.read_csv('Dataset/win/Emerald_I.csv')\n",
    "lose_Emerald_I = pd.read_csv('Dataset/lose/Emerald_I_lose.csv')\n",
    "win_Emerald_II = pd.read_csv('Dataset/win/Emerald_II.csv')\n",
    "lose_Emerald_II = pd.read_csv('Dataset/lose/Emerald_II_lose.csv')\n",
    "win_Emerald_III = pd.read_csv('Dataset/win/Emerald_III.csv')\n",
    "lose_Emerald_III = pd.read_csv('Dataset/lose/Emerald_III_lose.csv')\n",
    "win_Emerald_IV = pd.read_csv('Dataset/win/Emerald_IV.csv')\n",
    "lose_Emerald_IV = pd.read_csv('Dataset/lose/Emerald_IV_lose.csv')\n",
    "Emerald = pd.concat([win_Emerald_I, win_Emerald_II, win_Emerald_III, win_Emerald_IV, lose_Emerald_I, lose_Emerald_II, lose_Emerald_III, lose_Emerald_IV], ignore_index=True)\n",
    "print('Emerald : ', Emerald['result'].value_counts())\n",
    "\n",
    "win_Platinum_I = pd.read_csv('Dataset/win/Platinum_I.csv')\n",
    "lose_Platinum_I = pd.read_csv('Dataset/lose/Platinum_I_lose.csv')\n",
    "win_Platinum_II = pd.read_csv('Dataset/win/Platinum_II.csv')\n",
    "lose_Platinum_II = pd.read_csv('Dataset/lose/Platinum_II_lose.csv')\n",
    "win_Platinum_III = pd.read_csv('Dataset/win/Platinum_III.csv')\n",
    "lose_Platinum_III = pd.read_csv('Dataset/lose/Platinum_III_lose.csv')\n",
    "win_Platinum_IV = pd.read_csv('Dataset/win/Platinum_IV.csv')\n",
    "lose_Platinum_IV = pd.read_csv('Dataset/lose/Platinum_IV_lose.csv')\n",
    "Platinum = pd.concat([win_Platinum_I, win_Platinum_II, win_Platinum_III, win_Platinum_IV, lose_Platinum_I, lose_Platinum_II, lose_Platinum_III, lose_Platinum_IV], ignore_index=True)\n",
    "print('Platinum : ', Platinum['result'].value_counts())\n",
    "\n",
    "win_Gold_I = pd.read_csv('Dataset/win/Gold_I.csv')\n",
    "lose_Gold_I = pd.read_csv('Dataset/lose/Gold_I_lose.csv')\n",
    "win_Gold_II = pd.read_csv('Dataset/win/Gold_II.csv')\n",
    "lose_Gold_II = pd.read_csv('Dataset/lose/Gold_II_lose.csv')\n",
    "win_Gold_III= pd.read_csv('Dataset/win/Gold_III.csv')\n",
    "lose_Gold_III = pd.read_csv('Dataset/lose/Gold_III_lose.csv')\n",
    "win_Gold_IV = pd.read_csv('Dataset/win/Gold_IV.csv')\n",
    "lose_Gold_IV = pd.read_csv('Dataset/lose/Gold_IV_lose.csv')\n",
    "Gold = pd.concat([win_Gold_I, win_Gold_II, win_Gold_III, win_Gold_IV, lose_Gold_I, lose_Gold_II, lose_Gold_III, lose_Gold_IV], ignore_index=True)\n",
    "print('Gold : ', Gold['result'].value_counts())\n",
    "\n",
    "\n",
    "win_Silver_I = pd.read_csv('Dataset/win/Silver_I.csv')\n",
    "lose_Silver_I = pd.read_csv('Dataset/lose/Silver_I_lose.csv')\n",
    "win_Silver_II = pd.read_csv('Dataset/win/Silver_II.csv')\n",
    "lose_Silver_II = pd.read_csv('Dataset/lose/Silver_II_lose.csv')\n",
    "win_Silver_III = pd.read_csv('Dataset/win/Silver_III.csv')\n",
    "lose_Silver_III = pd.read_csv('Dataset/lose/Silver_III_lose.csv')\n",
    "win_Silver_IV = pd.read_csv('Dataset/win/Silver_IV.csv')\n",
    "lose_Silver_IV = pd.read_csv('Dataset/lose/Silver_IV_lose.csv')\n",
    "Silver = pd.concat([win_Silver_I, win_Silver_II, win_Silver_III, win_Silver_IV, lose_Silver_I, lose_Silver_II, lose_Silver_III, lose_Silver_IV], ignore_index=True)\n",
    "print('Silver : ', Silver['result'].value_counts())\n",
    "\n",
    "win_Bronze_I = pd.read_csv('Dataset/win/Bronze_I.csv')\n",
    "lose_Bronze_I = pd.read_csv('Dataset/lose/Bronze_I_lose.csv')\n",
    "win_Bronze_II = pd.read_csv('Dataset/win/Bronze_II.csv')\n",
    "lose_Bronze_II = pd.read_csv('Dataset/lose/Bronze_II_lose.csv')\n",
    "win_Bronze_III = pd.read_csv('Dataset/win/Bronze_III.csv')\n",
    "lose_Bronze_III = pd.read_csv('Dataset/lose/Bronze_III_lose.csv')\n",
    "win_Bronze_IV = pd.read_csv('Dataset/win/Bronze_IV.csv')\n",
    "lose_Bronze_IV = pd.read_csv('Dataset/lose/Bronze_IV_lose.csv')\n",
    "Bronze = pd.concat([win_Bronze_I, win_Bronze_II, win_Bronze_III, win_Bronze_IV, lose_Bronze_I, lose_Bronze_II, lose_Bronze_III, lose_Bronze_IV], ignore_index=True)\n",
    "print('Bronze : ', Bronze['result'].value_counts())\n",
    "\n",
    "win_Iron_I = pd.read_csv('Dataset/win/Iron_I.csv')\n",
    "lose_Iron_I = pd.read_csv('Dataset/lose/Iron_I_lose.csv')\n",
    "win_Iron_II = pd.read_csv('Dataset/win/Iron_II.csv')\n",
    "lose_Iron_II = pd.read_csv('Dataset/lose/Iron_II_lose.csv')\n",
    "win_Iron_III = pd.read_csv('Dataset/win/Iron_III.csv')\n",
    "lose_Iron_III = pd.read_csv('Dataset/lose/Iron_III_lose.csv')\n",
    "win_Iron_IV = pd.read_csv('Dataset/win/Iron_IV.csv')\n",
    "lose_Iron_IV = pd.read_csv('Dataset/lose/Iron_IV_lose.csv')\n",
    "Iron = pd.concat([win_Iron_I, win_Iron_II, win_Iron_III, win_Iron_IV, lose_Iron_I, lose_Iron_II, lose_Iron_III, lose_Iron_IV], ignore_index=True)\n",
    "print('Iron : ', Iron['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76b440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=50, random_state = 10)\n",
    "lgbm = LGBMClassifier(n_estimators=100, verbosity=0)\n",
    "cat = CatBoostClassifier(iterations=2, depth=2, learning_rate=1)\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.2, max_depth=4, random_state = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f4caf",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad12b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 스케일링 방법과 정확도, confusion matrix를 비교하기 위한 원본\n",
    "def def_original(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         np_X_train = X_train.values\n",
    "#         X_train_data = np_X_train.reshape((X_train.shape[1]*X_train.shape[0]), 1)\n",
    "#         plt.hist(X_train_data, bins=30, color= 'red', alpha = 0.7)\n",
    "#         plt.title('before data scaling')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed578851",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c25c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0, 분산이 1인 정규분포를 갖도록 만들어준다(표준화).\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def def_StandardScaler(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    std = StandardScaler()\n",
    "    # train data는 fit 메서드를 적용시킨 후 transform, test data는 transform\n",
    "    std.fit(X_train)\n",
    "    std_X_train_scaled = std.transform(X_train)\n",
    "    std_X_test_scaled = std.transform(X_test)\n",
    "    \n",
    "    X_train = std_X_train_scaled\n",
    "    X_test = std_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         X_train_scaled_ss = std_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(X_train_scaled_ss, bins=30, alpha = 0.7, density = True)\n",
    "#         plt.title('StandardScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e65181",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f57ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 피처들이 0과 1사이의 데이터값을 갖도록 함. 최솟값 0, 최댓값 1\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def def_MinMaxScaler(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    mms = MinMaxScaler()\n",
    "    mms.fit(X_train)\n",
    "    mms_X_train_scaled = mms.transform(X_train)\n",
    "    mms_X_test_scaled = mms.transform(X_test)\n",
    "\n",
    "    X_train = mms_X_train_scaled\n",
    "    X_test = mms_X_test_scaled\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         mms_X_train_scaled_reshape = mms_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(mms_X_train_scaled_reshape, bins=30, color='green', alpha = 0.7)\n",
    "#         plt.title('MinMaxScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c99d46",
   "metadata": {},
   "source": [
    "# MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca0db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 피처들의 절댓값이 0과 1 사이\n",
    "# 데이터가 -1과 1사이의 범위에 존재\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "def def_MaxAbsScaler(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    mas = MaxAbsScaler()\n",
    "    mas.fit(X_train)\n",
    "    mas_X_train_scaled = mas.transform(X_train)\n",
    "    mas_X_test_scaled = mas.transform(X_test)\n",
    "    \n",
    "    X_train = mas_X_train_scaled\n",
    "    X_test = mas_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         mas_X_train_scaled_reshape = mas_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(mas_X_train_scaled_reshape, bins=30, color='yellow', alpha = 0.7)\n",
    "#         plt.title('MaxAbsScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aca5b7",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c567e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler는 평균과 분산을 사용했지만, RobustScaler는 중간값(median)과 사분위값(quartile)을 사용\n",
    "# 따라서 이상치의 영향을 최소화할 수 있음.\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "def def_RobustScaler(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    rbs = RobustScaler()\n",
    "    rbs_X_train_scaled = rbs.fit_transform(X_train)\n",
    "    rbs_X_test_scaled = rbs.transform(X_test)\n",
    "\n",
    "    X_train = rbs_X_train_scaled\n",
    "    X_test = rbs_X_test_scaled\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         rbs_X_train_scaled_reshape = rbs_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(rbs_X_train_scaled_reshape, bins=30, color='pink', alpha = 0.7)\n",
    "#         plt.title('RobustScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e64e4",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed318525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 4가지 방법은 열을 대상으로 진행, Normalizer는 각 행(row)마다 정규화\n",
    "# 한 행의 모든 피처들 사이의 유클리드 거리가 1이 되도록 데이터값을 만들어준다.\n",
    "from sklearn.preprocessing import Normalizer\n",
    "def def_Normalizer(data, showGraph):\n",
    "    X = data.iloc[:, :20]\n",
    "    y = data.iloc[:, 20:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    norm = Normalizer()\n",
    "    norm_X_train_scaled = norm.fit_transform(X_train)\n",
    "    norm_X_test_scaled = norm.transform(X_test)\n",
    "    \n",
    "    X_train = norm_X_train_scaled\n",
    "    X_test = norm_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    xgb_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         norm_X_train_scaled_reshape = norm_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(norm_X_train_scaled_reshape, bins=30, color='orange', alpha = 0.7)\n",
    "#         plt.title('Normalizer')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ef1efe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.79\n",
      "TN:1404 FP:470 FN:531 TP:1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 LGBM 정확도 : 74.08\n",
      "TN:1413 FP:461 FN:529 TP:1416\n",
      "0:\tlearn: 0.5830847\ttotal: 141ms\tremaining: 141ms\n",
      "1:\tlearn: 0.5645379\ttotal: 143ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 72.37\n",
      "TN:1318 FP:556 FN:499 TP:1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 72.82\n",
      "TN:1401 FP:473 FN:565 TP:1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 74.02\n",
      "TN:1404 FP:470 FN:522 TP:1423\n",
      "원본 LGBM 정확도 : 74.08\n",
      "TN:1413 FP:461 FN:529 TP:1416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5830847\ttotal: 2.09ms\tremaining: 2.09ms\n",
      "1:\tlearn: 0.5645379\ttotal: 5.99ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 72.37\n",
      "TN:1318 FP:556 FN:499 TP:1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 72.82\n",
      "TN:1401 FP:473 FN:565 TP:1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.84\n",
      "TN:1402 FP:472 FN:527 TP:1418\n",
      "원본 LGBM 정확도 : 74.18\n",
      "TN:1413 FP:461 FN:525 TP:1420\n",
      "0:\tlearn: 0.5830847\ttotal: 1.81ms\tremaining: 1.81ms\n",
      "1:\tlearn: 0.5645379\ttotal: 3.8ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 72.37\n",
      "TN:1318 FP:556 FN:499 TP:1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 72.77\n",
      "TN:1399 FP:475 FN:565 TP:1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.95\n",
      "TN:1407 FP:467 FN:528 TP:1417\n",
      "원본 LGBM 정확도 : 74.08\n",
      "TN:1413 FP:461 FN:529 TP:1416\n",
      "0:\tlearn: 0.5830847\ttotal: 1.85ms\tremaining: 1.85ms\n",
      "1:\tlearn: 0.5645379\ttotal: 3.76ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 72.37\n",
      "TN:1318 FP:556 FN:499 TP:1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 72.82\n",
      "TN:1401 FP:473 FN:565 TP:1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.97\n",
      "TN:1407 FP:467 FN:527 TP:1418\n",
      "원본 LGBM 정확도 : 74.08\n",
      "TN:1413 FP:461 FN:529 TP:1416\n",
      "0:\tlearn: 0.5830847\ttotal: 2.09ms\tremaining: 2.09ms\n",
      "1:\tlearn: 0.5645379\ttotal: 4.08ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 72.37\n",
      "TN:1318 FP:556 FN:499 TP:1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 72.82\n",
      "TN:1401 FP:473 FN:565 TP:1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.76\n",
      "TN:1404 FP:470 FN:532 TP:1413\n",
      "원본 LGBM 정확도 : 73.45\n",
      "TN:1418 FP:456 FN:558 TP:1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5886814\ttotal: 3.5ms\tremaining: 3.5ms\n",
      "1:\tlearn: 0.5743925\ttotal: 5.88ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 73.63\n",
      "TN:1312 FP:562 FN:445 TP:1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 74.18\n",
      "TN:1424 FP:450 FN:536 TP:1409\n"
     ]
    }
   ],
   "source": [
    "# SMOTE, SMOTENC, SMOTEN, ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE \n",
    "# showGraph -> confusion matrix 출력 여부\n",
    "data, showGraph = Grandmaster, False\n",
    "data= data.drop(['matchId'],axis=1)\n",
    "data= data.drop(['queueId'],axis=1)\n",
    "data= data.drop(['K-WIN-top'],axis=1)\n",
    "data= data.drop(['K-LOSE-top'],axis=1)\n",
    "data= data.drop(['K-WIN-jug'],axis=1)\n",
    "data= data.drop(['K-LOSE-jug'],axis=1)\n",
    "data= data.drop(['K-WIN-mid'],axis=1)\n",
    "data= data.drop(['K-LOSE-mid'],axis=1)\n",
    "data= data.drop(['K-WIN-ad'],axis=1)\n",
    "data= data.drop(['K-LOSE-ad'],axis=1)\n",
    "data= data.drop(['K-WIN-sup'],axis=1)\n",
    "data= data.drop(['K-LOSE-sup'],axis=1)\n",
    "data= data.drop(['LOSE_controlWARDPlaced'],axis=1)\n",
    "data= data.drop(['WIN_controlWARDPlaced'],axis=1)\n",
    "data= data.drop(['Diff-A'],axis=1)\n",
    "def_original(data, showGraph)\n",
    "def_StandardScaler(data, showGraph)\n",
    "def_MinMaxScaler(data, showGraph)\n",
    "def_MaxAbsScaler(data, showGraph)\n",
    "def_RobustScaler(data, showGraph)\n",
    "def_Normalizer(data, showGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f44ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
