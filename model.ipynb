{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chanllenger :  result\n",
      " 1    4836\n",
      "-1    4836\n",
      "Name: count, dtype: int64\n",
      "Grandmaster :  result\n",
      " 1    6365\n",
      "-1    6365\n",
      "Name: count, dtype: int64\n",
      "Master :  result\n",
      " 1    8838\n",
      "-1    8838\n",
      "Name: count, dtype: int64\n",
      "Emerald :  result\n",
      " 1    18621\n",
      "-1    18621\n",
      "Name: count, dtype: int64\n",
      "Platinum :  result\n",
      " 1    19067\n",
      "-1    19067\n",
      "Name: count, dtype: int64\n",
      "Gold :  result\n",
      " 1    11332\n",
      "-1    11332\n",
      "Name: count, dtype: int64\n",
      "Silver :  result\n",
      " 1    13167\n",
      "-1    13167\n",
      "Name: count, dtype: int64\n",
      "Bronze :  result\n",
      " 1    19057\n",
      "-1    19057\n",
      "Name: count, dtype: int64\n",
      "Iron :  result\n",
      " 1    18524\n",
      "-1    18524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "win_10_Chanllenger = pd.read_csv('Dataset/win_10/10_Chanllenger.csv')\n",
    "lose_10_Chanllenger = pd.read_csv('Dataset/lose_10/10_Chanllenger_lose.csv')\n",
    "win_10_Chanllenger_ver2 = pd.read_csv('Dataset/win_10/10_Chanllenger_ver2.csv')\n",
    "lose_10_Chanllenger_ver2 = pd.read_csv('Dataset/lose_10/10_Chanllenger_ver2_lose.csv')\n",
    "Chanllenger1 = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "Chanllenger2 = pd.concat([win_10_Chanllenger_ver2, lose_10_Chanllenger_ver2], ignore_index=True)\n",
    "Chanllenger = pd.concat([Chanllenger1, Chanllenger2], ignore_index=True)\n",
    "print('Chanllenger : ', Chanllenger['result'].value_counts())\n",
    "\n",
    "win_10_Grandmaster = pd.read_csv('Dataset/win_10/10_Grandmaster.csv')\n",
    "lose_10_Grandmaster = pd.read_csv('Dataset/lose_10/10_Grandmaster.csv')\n",
    "be_10_Grandmaster = pd.read_csv('Dataset/lose_10/be_10_Grandmaster.csv')\n",
    "Grandmaster = pd.concat([win_10_Grandmaster, be_10_Grandmaster], ignore_index=True)\n",
    "print('Grandmaster : ', Grandmaster['result'].value_counts())\n",
    "\n",
    "# win_Chanllenger = pd.read_csv('Dataset/win/Chanllenger.csv')\n",
    "# lose_Chanllenger = pd.read_csv('Dataset/lose/Chanllenger_lose.csv')\n",
    "# Chanllenger = pd.concat([win_Chanllenger, lose_Chanllenger], ignore_index=True)\n",
    "# print(Chanllenger['result'].value_counts())\n",
    "\n",
    "# win_Grandmaster = pd.read_csv('Dataset/win/Grandmaster.csv')\n",
    "# lose_Grandmaster = pd.read_csv('Dataset/lose/Grandmaster_lose.csv')\n",
    "# Grandmaster = pd.concat([win_Grandmaster, lose_Grandmaster], ignore_index=True)\n",
    "\n",
    "win_Master = pd.read_csv('Dataset/win/Master.csv')\n",
    "lose_Master = pd.read_csv('Dataset/lose/Master_lose.csv')\n",
    "Master = pd.concat([win_Master, lose_Master], ignore_index=True)\n",
    "print('Master : ', Master['result'].value_counts())\n",
    "\n",
    "win_Emerald_I = pd.read_csv('Dataset/win/Emerald_I.csv')\n",
    "lose_Emerald_I = pd.read_csv('Dataset/lose/Emerald_I_lose.csv')\n",
    "win_Emerald_II = pd.read_csv('Dataset/win/Emerald_II.csv')\n",
    "lose_Emerald_II = pd.read_csv('Dataset/lose/Emerald_II_lose.csv')\n",
    "win_Emerald_III = pd.read_csv('Dataset/win/Emerald_III.csv')\n",
    "lose_Emerald_III = pd.read_csv('Dataset/lose/Emerald_III_lose.csv')\n",
    "win_Emerald_IV = pd.read_csv('Dataset/win/Emerald_IV.csv')\n",
    "lose_Emerald_IV = pd.read_csv('Dataset/lose/Emerald_IV_lose.csv')\n",
    "Emerald = pd.concat([win_Emerald_I, win_Emerald_II, win_Emerald_III, win_Emerald_IV, lose_Emerald_I, lose_Emerald_II, lose_Emerald_III, lose_Emerald_IV], ignore_index=True)\n",
    "print('Emerald : ', Emerald['result'].value_counts())\n",
    "\n",
    "win_Platinum_I = pd.read_csv('Dataset/win/Platinum_I.csv')\n",
    "lose_Platinum_I = pd.read_csv('Dataset/lose/Platinum_I_lose.csv')\n",
    "win_Platinum_II = pd.read_csv('Dataset/win/Platinum_II.csv')\n",
    "lose_Platinum_II = pd.read_csv('Dataset/lose/Platinum_II_lose.csv')\n",
    "win_Platinum_III = pd.read_csv('Dataset/win/Platinum_III.csv')\n",
    "lose_Platinum_III = pd.read_csv('Dataset/lose/Platinum_III_lose.csv')\n",
    "win_Platinum_IV = pd.read_csv('Dataset/win/Platinum_IV.csv')\n",
    "lose_Platinum_IV = pd.read_csv('Dataset/lose/Platinum_IV_lose.csv')\n",
    "Platinum = pd.concat([win_Platinum_I, win_Platinum_II, win_Platinum_III, win_Platinum_IV, lose_Platinum_I, lose_Platinum_II, lose_Platinum_III, lose_Platinum_IV], ignore_index=True)\n",
    "print('Platinum : ', Platinum['result'].value_counts())\n",
    "\n",
    "win_Gold_I = pd.read_csv('Dataset/win/Gold_I.csv')\n",
    "lose_Gold_I = pd.read_csv('Dataset/lose/Gold_I_lose.csv')\n",
    "win_Gold_II = pd.read_csv('Dataset/win/Gold_II.csv')\n",
    "lose_Gold_II = pd.read_csv('Dataset/lose/Gold_II_lose.csv')\n",
    "win_Gold_III= pd.read_csv('Dataset/win/Gold_III.csv')\n",
    "lose_Gold_III = pd.read_csv('Dataset/lose/Gold_III_lose.csv')\n",
    "win_Gold_IV = pd.read_csv('Dataset/win/Gold_IV.csv')\n",
    "lose_Gold_IV = pd.read_csv('Dataset/lose/Gold_IV_lose.csv')\n",
    "Gold = pd.concat([win_Gold_I, win_Gold_II, win_Gold_III, win_Gold_IV, lose_Gold_I, lose_Gold_II, lose_Gold_III, lose_Gold_IV], ignore_index=True)\n",
    "print('Gold : ', Gold['result'].value_counts())\n",
    "\n",
    "\n",
    "win_Silver_I = pd.read_csv('Dataset/win/Silver_I.csv')\n",
    "lose_Silver_I = pd.read_csv('Dataset/lose/Silver_I_lose.csv')\n",
    "win_Silver_II = pd.read_csv('Dataset/win/Silver_II.csv')\n",
    "lose_Silver_II = pd.read_csv('Dataset/lose/Silver_II_lose.csv')\n",
    "win_Silver_III = pd.read_csv('Dataset/win/Silver_III.csv')\n",
    "lose_Silver_III = pd.read_csv('Dataset/lose/Silver_III_lose.csv')\n",
    "win_Silver_IV = pd.read_csv('Dataset/win/Silver_IV.csv')\n",
    "lose_Silver_IV = pd.read_csv('Dataset/lose/Silver_IV_lose.csv')\n",
    "Silver = pd.concat([win_Silver_I, win_Silver_II, win_Silver_III, win_Silver_IV, lose_Silver_I, lose_Silver_II, lose_Silver_III, lose_Silver_IV], ignore_index=True)\n",
    "print('Silver : ', Silver['result'].value_counts())\n",
    "\n",
    "win_Bronze_I = pd.read_csv('Dataset/win/Bronze_I.csv')\n",
    "lose_Bronze_I = pd.read_csv('Dataset/lose/Bronze_I_lose.csv')\n",
    "win_Bronze_II = pd.read_csv('Dataset/win/Bronze_II.csv')\n",
    "lose_Bronze_II = pd.read_csv('Dataset/lose/Bronze_II_lose.csv')\n",
    "win_Bronze_III = pd.read_csv('Dataset/win/Bronze_III.csv')\n",
    "lose_Bronze_III = pd.read_csv('Dataset/lose/Bronze_III_lose.csv')\n",
    "win_Bronze_IV = pd.read_csv('Dataset/win/Bronze_IV.csv')\n",
    "lose_Bronze_IV = pd.read_csv('Dataset/lose/Bronze_IV_lose.csv')\n",
    "Bronze = pd.concat([win_Bronze_I, win_Bronze_II, win_Bronze_III, win_Bronze_IV, lose_Bronze_I, lose_Bronze_II, lose_Bronze_III, lose_Bronze_IV], ignore_index=True)\n",
    "print('Bronze : ', Bronze['result'].value_counts())\n",
    "\n",
    "win_Iron_I = pd.read_csv('Dataset/win/Iron_I.csv')\n",
    "lose_Iron_I = pd.read_csv('Dataset/lose/Iron_I_lose.csv')\n",
    "win_Iron_II = pd.read_csv('Dataset/win/Iron_II.csv')\n",
    "lose_Iron_II = pd.read_csv('Dataset/lose/Iron_II_lose.csv')\n",
    "win_Iron_III = pd.read_csv('Dataset/win/Iron_III.csv')\n",
    "lose_Iron_III = pd.read_csv('Dataset/lose/Iron_III_lose.csv')\n",
    "win_Iron_IV = pd.read_csv('Dataset/win/Iron_IV.csv')\n",
    "lose_Iron_IV = pd.read_csv('Dataset/lose/Iron_IV_lose.csv')\n",
    "Iron = pd.concat([win_Iron_I, win_Iron_II, win_Iron_III, win_Iron_IV, lose_Iron_I, lose_Iron_II, lose_Iron_III, lose_Iron_IV], ignore_index=True)\n",
    "print('Iron : ', Iron['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=50, random_state = 10)\n",
    "lgbm = LGBMClassifier(n_estimators=100)\n",
    "cat = CatBoostClassifier(iterations=2, depth=2, learning_rate=1)\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "data = Chanllenger\n",
    "\n",
    "data= data.drop(['matchId'],axis=1)\n",
    "data= data.drop(['queueId'],axis=1)\n",
    "data= data.drop(['K-WIN-top'],axis=1)\n",
    "data= data.drop(['K-LOSE-top'],axis=1)\n",
    "data= data.drop(['K-WIN-jug'],axis=1)\n",
    "data= data.drop(['K-LOSE-jug'],axis=1)\n",
    "data= data.drop(['K-WIN-mid'],axis=1)\n",
    "data= data.drop(['K-LOSE-mid'],axis=1)\n",
    "data= data.drop(['K-WIN-ad'],axis=1)\n",
    "data= data.drop(['K-LOSE-ad'],axis=1)\n",
    "data= data.drop(['K-WIN-sup'],axis=1)\n",
    "data= data.drop(['K-LOSE-sup'],axis=1)\n",
    "data= data.drop(['LOSE_controlWARDPlaced'],axis=1)\n",
    "data= data.drop(['WIN_controlWARDPlaced'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest : 77.5 %\n",
      "RandomForest f1 : 77.33 %\n",
      "[LightGBM] [Info] Number of positive: 3376, number of negative: 3394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 6770, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498671 -> initscore=-0.005318\n",
      "[LightGBM] [Info] Start training from score -0.005318\n",
      "lightGBM : 78.19 %\n",
      "lightGBM f1 : 78.25 %\n",
      "0:\tlearn: 0.5472638\ttotal: 2.44ms\tremaining: 2.44ms\n",
      "1:\tlearn: 0.5220640\ttotal: 5.14ms\tremaining: 0us\n",
      "CatBoost : 75.09 %\n",
      "CatBoost f1 : 74.43 %\n",
      "ExtraTrees : 75.91 %\n",
      "ExtraTrees f1 : 75.62 %\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :21]\n",
    "y = data.iloc[:, 21:]\n",
    "# # features/target, train/test dataset 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "train_y = train_y.values.ravel()\n",
    "rf.fit(train_x, train_y)\n",
    "rf_pre = rf.predict(test_x)\n",
    "print(\"RandomForest :\", round(accuracy_score(test_y, rf_pre)*100, 2), \"%\")\n",
    "print(\"RandomForest f1 :\", round(f1_score(test_y, rf_pre)*100, 2), \"%\")\n",
    "lgbm.fit(train_x, train_y)\n",
    "lgbm_pre = lgbm.predict(test_x)\n",
    "print(\"lightGBM :\", round(accuracy_score(test_y, lgbm_pre)*100, 2), \"%\")\n",
    "print(\"lightGBM f1 :\", round(f1_score(test_y, lgbm_pre)*100, 2), \"%\")\n",
    "cat.fit(train_x, train_y)\n",
    "cat_pre = cat.predict(test_x)\n",
    "print(\"CatBoost :\", round(accuracy_score(test_y, cat_pre)*100, 2), \"%\")\n",
    "print(\"CatBoost f1 :\", round(f1_score(test_y, cat_pre)*100, 2), \"%\")\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "et.fit(train_x, train_y)\n",
    "et_pre = et.predict(test_x)\n",
    "print(\"ExtraTrees :\", round(accuracy_score(test_y, et_pre)*100, 2), \"%\")\n",
    "print(\"ExtraTrees f1 :\", round(f1_score(test_y, et_pre)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest : 78.04 %\n",
      "RandomForest f1 : 77.88 %\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=50, random_state = 10)\n",
    "rf.fit(train_x,train_y)\n",
    "rf_pre = rf.predict(test_x)\n",
    "print(\"RandomForest :\", round(accuracy_score(test_y, rf_pre)*100, 2), \"%\")\n",
    "print(\"RandomForest f1 :\", round(f1_score(test_y, rf_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3878, number of negative: 3859\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 654\n",
      "[LightGBM] [Info] Number of data points in the train set: 7737, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501228 -> initscore=0.004911\n",
      "[LightGBM] [Info] Start training from score 0.004911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM : 77.0 %\n",
      "lightGBM f1 : 77.24 %\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=100)\n",
    "lgbm.fit(train_x, train_y)\n",
    "lgbm_pre = lgbm.predict(test_x)\n",
    "print(\"lightGBM :\", round(accuracy_score(test_y, lgbm_pre)*100, 2), \"%\")\n",
    "print(\"lightGBM f1 :\", round(f1_score(test_y, lgbm_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5525126\ttotal: 4.09ms\tremaining: 4.09ms\n",
      "1:\tlearn: 0.5221295\ttotal: 8.18ms\tremaining: 0us\n",
      "CatBoost : 75.45 %\n",
      "CatBoost f1 : 73.8 %\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=2, depth=2, learning_rate=1)\n",
    "cat.fit(train_x, train_y)\n",
    "cat_pre = cat.predict(test_x)\n",
    "print(\"CatBoost :\", round(accuracy_score(test_y, cat_pre)*100, 2), \"%\")\n",
    "print(\"CatBoost f1 :\", round(f1_score(test_y, cat_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees : 77.21 %\n",
      "ExtraTrees f1 : 76.85 %\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "et.fit(train_x, train_y)\n",
    "et_pre = et.predict(test_x)\n",
    "print(\"ExtraTrees :\", round(accuracy_score(test_y, et_pre)*100, 2), \"%\")\n",
    "print(\"ExtraTrees f1 :\", round(f1_score(test_y, et_pre)*100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
