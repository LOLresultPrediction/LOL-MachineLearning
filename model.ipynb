{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      " 1    2420\n",
      "-1    2420\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/lose/Grandmaster.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rnjsd\\OneDrive - 인하대학교\\권우영\\인하대학교\\2학년\\강의\\(2-2)데이터사이언스\\TeamProject\\코드\\model.ipynb 셀 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rnjsd/OneDrive%20-%20%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/%EA%B6%8C%EC%9A%B0%EC%98%81/%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/2%ED%95%99%EB%85%84/%EA%B0%95%EC%9D%98/%282-2%29%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4/TeamProject/%EC%BD%94%EB%93%9C/model.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(Chanllenger[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rnjsd/OneDrive%20-%20%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/%EA%B6%8C%EC%9A%B0%EC%98%81/%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/2%ED%95%99%EB%85%84/%EA%B0%95%EC%9D%98/%282-2%29%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4/TeamProject/%EC%BD%94%EB%93%9C/model.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m win_Grandmaster \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mDataset/win/Grandmaster.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rnjsd/OneDrive%20-%20%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/%EA%B6%8C%EC%9A%B0%EC%98%81/%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/2%ED%95%99%EB%85%84/%EA%B0%95%EC%9D%98/%282-2%29%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4/TeamProject/%EC%BD%94%EB%93%9C/model.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m lose_Grandmaster \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mDataset/lose/Grandmaster.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rnjsd/OneDrive%20-%20%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/%EA%B6%8C%EC%9A%B0%EC%98%81/%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/2%ED%95%99%EB%85%84/%EA%B0%95%EC%9D%98/%282-2%29%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4/TeamProject/%EC%BD%94%EB%93%9C/model.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Grandmaster \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([win_Grandmaster, lose_Grandmaster], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rnjsd/OneDrive%20-%20%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/%EA%B6%8C%EC%9A%B0%EC%98%81/%EC%9D%B8%ED%95%98%EB%8C%80%ED%95%99%EA%B5%90/2%ED%95%99%EB%85%84/%EA%B0%95%EC%9D%98/%282-2%29%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4/TeamProject/%EC%BD%94%EB%93%9C/model.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(Grandmaster[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts())\n",
      "File \u001b[1;32mc:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\rnjsd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/lose/Grandmaster.csv'"
     ]
    }
   ],
   "source": [
    "# Chanllenger = pd.read_csv('Dataset/win_10/10_Chanllenger.csv')\n",
    "# Chanllenger = pd.read_csv('Dataset/lose_10/10_Chanllenger.csv')\n",
    "# Chanllenger_ver2 = pd.read_csv('Dataset/win_10/10_Chanllenger_ver2.csv')\n",
    "# Chanllenger_ver2 = pd.read_csv('Dataset/lose_10/10_Chanllenger_ver2.csv')\n",
    "# win_10_Grandmaster = pd.read_csv('Dataset/win_10/win_10_Grandmaster.csv')\n",
    "# lose_10_Grandmaster = pd.read_csv('Dataset/lose_10/lose_10_Grandmaster.csv')\n",
    "\n",
    "win_Chanllenger = pd.read_csv('Dataset/win/Chanllenger.csv')\n",
    "lose_Chanllenger = pd.read_csv('Dataset/lose/Chanllenger_lose.csv')\n",
    "Chanllenger = pd.concat([win_Chanllenger, lose_Chanllenger], ignore_index=True)\n",
    "print(Chanllenger['result'].value_counts())\n",
    "\n",
    "win_Grandmaster = pd.read_csv('Dataset/win/Grandmaster.csv')\n",
    "lose_Grandmaster = pd.read_csv('Dataset/lose/Grandmaster_lose.csv')\n",
    "Grandmaster = pd.concat([win_Grandmaster, lose_Grandmaster], ignore_index=True)\n",
    "print(Grandmaster['result'].value_counts())\n",
    "\n",
    "win_Master = pd.read_csv('Dataset/win/Master.csv')\n",
    "lose_Master = pd.read_csv('Dataset/lose/Master_lose.csv')\n",
    "Master = pd.concat([win_Master, lose_Master], ignore_index=True)\n",
    "print(Master['result'].value_counts())\n",
    "\n",
    "win_Emerald_I = pd.read_csv('Dataset/win/Emerald_I.csv')\n",
    "lose_Emerald_I = pd.read_csv('Dataset/lose/Emerald_I.csv')\n",
    "win_Emerald_II = pd.read_csv('Dataset/win/Emerald_II.csv')\n",
    "lose_Emerald_II = pd.read_csv('Dataset/lose/Emerald_II.csv')\n",
    "win_Emerald_III = pd.read_csv('Dataset/win/Emerald_III.csv')\n",
    "lose_Emerald_III = pd.read_csv('Dataset/lose/Emerald_III.csv')\n",
    "win_Emerald_IV = pd.read_csv('Dataset/win/Emerald_IV.csv')\n",
    "lose_Emerald_IV = pd.read_csv('Dataset/lose/Emerald_IV.csv')\n",
    "Emerald = pd.concat([win_Emerald_I, win_Emerald_II, win_Emerald_III, win_Emerald_IV, lose_Emerald_I, lose_Emerald_II, lose_Emerald_III, lose_Emerald_IV], ignore_index=True)\n",
    "print(Emerald['result'].value_counts())\n",
    "\n",
    "win_Platinum_I = pd.read_csv('Dataset/win/Platinum_I.csv')\n",
    "lose_Platinum_I = pd.read_csv('Dataset/lose/Platinum_I.csv')\n",
    "win_Platinum_II = pd.read_csv('Dataset/win/Platinum_II.csv')\n",
    "lose_Platinum_II = pd.read_csv('Dataset/lose/Platinum_II.csv')\n",
    "win_Platinum_III = pd.read_csv('Dataset/win/Platinum_III.csv')\n",
    "lose_Platinum_III = pd.read_csv('Dataset/lose/Platinum_III.csv')\n",
    "win_Platinum_IV = pd.read_csv('Dataset/win/Platinum_IV.csv')\n",
    "lose_Platinum_IV = pd.read_csv('Dataset/lose/Platinum_IV.csv')\n",
    "Platinum = pd.concat([win_Platinum_I, win_Platinum_II, win_Platinum_III, win_Platinum_IV, lose_Platinum_I, lose_Platinum_II, lose_Platinum_III, lose_Platinum_IV], ignore_index=True)\n",
    "print(Platinum['result'].value_counts())\n",
    "\n",
    "win_Gold_I = pd.read_csv('Dataset/win/Gold_I.csv')\n",
    "lose_Gold_I = pd.read_csv('Dataset/lose/Gold_I.csv')\n",
    "win_Gold_II = pd.read_csv('Dataset/win/Gold_II.csv')\n",
    "lose_Gold_II = pd.read_csv('Dataset/lose/Gold_II.csv')\n",
    "win_Gold_III= pd.read_csv('Dataset/win/Gold_III.csv')\n",
    "lose_Gold_III = pd.read_csv('Dataset/lose/Gold_III.csv')\n",
    "win_Gold_IV = pd.read_csv('Dataset/win/Gold_IV.csv')\n",
    "lose_Gold_IV = pd.read_csv('Dataset/lose/Gold_IV.csv')\n",
    "Gold = pd.concat([win_Gold_I, win_Gold_II, win_Gold_III, win_Gold_IV, lose_Gold_I, lose_Gold_II, lose_Gold_III, lose_Gold_IV], ignore_index=True)\n",
    "print(Gold['result'].value_counts())\n",
    "\n",
    "\n",
    "win_Silver_I = pd.read_csv('Dataset/win/Silver_I.csv')\n",
    "lose_Silver_I = pd.read_csv('Dataset/lose/Silver_I.csv')\n",
    "win_Silver_II = pd.read_csv('Dataset/win/Silver_II.csv')\n",
    "lose_Silver_II = pd.read_csv('Dataset/lose/Silver_II.csv')\n",
    "win_Silver_III = pd.read_csv('Dataset/win/Silver_III.csv')\n",
    "lose_Silver_III = pd.read_csv('Dataset/lose/Silver_III.csv')\n",
    "win_Silver_IV = pd.read_csv('Dataset/win/Silver_IV.csv')\n",
    "lose_Silver_IV = pd.read_csv('Dataset/lose/Silver_IV.csv')\n",
    "Silver = pd.concat([win_Silver_I, win_Silver_II, win_Silver_III, win_Silver_IV, lose_Silver_I, lose_Silver_II, lose_Silver_III, lose_Silver_IV], ignore_index=True)\n",
    "print(Silver['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "data2 = pd.concat([win_Chanllenger_ver2, lose_Chanllenger_ver2], ignore_index=True)\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "# data = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "# data = pd.concat([win_Silver, lose_Silver], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 무의미한 변수 제거\n",
    "data= data.drop(['matchId'],axis=1)\n",
    "data= data.drop(['queueId'],axis=1)\n",
    "data= data.drop(['K-WIN-top'],axis=1)\n",
    "data= data.drop(['K-LOSE-top'],axis=1)\n",
    "data= data.drop(['K-WIN-jug'],axis=1)\n",
    "data= data.drop(['K-LOSE-jug'],axis=1)\n",
    "data= data.drop(['K-WIN-mid'],axis=1)\n",
    "data= data.drop(['K-LOSE-mid'],axis=1)\n",
    "data= data.drop(['K-WIN-ad'],axis=1)\n",
    "data= data.drop(['K-LOSE-ad'],axis=1)\n",
    "data= data.drop(['K-WIN-sup'],axis=1)\n",
    "data= data.drop(['K-LOSE-sup'],axis=1)\n",
    "data= data.drop(['LOSE_controlWARDPlaced'],axis=1)\n",
    "data= data.drop(['WIN_controlWARDPlaced'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :21]\n",
    "y = data.iloc[:, 21:]\n",
    "\n",
    "# # features/target, train/test dataset 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest : 86.97 %\n",
      "RandomForest f1 : 87.05 %\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state = 10)\n",
    "rf.fit(train_x,train_y)\n",
    "rf_pre = rf.predict(test_x)\n",
    "print(\"RandomForest :\", round(accuracy_score(test_y, rf_pre)*100, 2), \"%\")\n",
    "print(\"RandomForest f1 :\", round(f1_score(test_y, rf_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3376, number of negative: 3394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 6770, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498671 -> initscore=-0.005318\n",
      "[LightGBM] [Info] Start training from score -0.005318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM : 87.32 %\n",
      "lightGBM f1 : 87.53 %\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=100)\n",
    "lgbm.fit(train_x, train_y)\n",
    "lgbm_pre = lgbm.predict(test_x)\n",
    "print(\"lightGBM :\", round(accuracy_score(test_y, lgbm_pre)*100, 2), \"%\")\n",
    "print(\"lightGBM f1 :\", round(f1_score(test_y, lgbm_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4409085\ttotal: 11.5ms\tremaining: 11.5ms\n",
      "1:\tlearn: 0.4248691\ttotal: 14.2ms\tremaining: 0us\n",
      "CatBoost : 82.77 %\n",
      "CatBoost f1 : 82.37 %\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=2, depth=2, learning_rate=1)\n",
    "cat.fit(train_x, train_y)\n",
    "cat_pre = cat.predict(test_x)\n",
    "print(\"CatBoost :\", round(accuracy_score(test_y, cat_pre)*100, 2), \"%\")\n",
    "print(\"CatBoost f1 :\", round(f1_score(test_y, cat_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees : 83.39 %\n",
      "ExtraTrees f1 : 83.5 %\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "et.fit(train_x, train_y)\n",
    "et_pre = et.predict(test_x)\n",
    "print(\"ExtraTrees :\", round(accuracy_score(test_y, et_pre)*100, 2), \"%\")\n",
    "print(\"ExtraTrees f1 :\", round(f1_score(test_y, et_pre)*100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
