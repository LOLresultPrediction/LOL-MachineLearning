{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      " 1    2420\n",
      "-1    2420\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    6353\n",
      "-1    6353\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    8838\n",
      "-1    8838\n",
      "Name: count, dtype: int64\n",
      "result\n",
      "1    8838\n",
      "Name: count, dtype: int64\n",
      "result\n",
      "-1    8838\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    18621\n",
      "-1    18621\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    19067\n",
      "-1    19067\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    11332\n",
      "-1    11332\n",
      "Name: count, dtype: int64\n",
      "result\n",
      " 1    13167\n",
      "-1    13167\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Chanllenger = pd.read_csv('Dataset/win_10/10_Chanllenger.csv')\n",
    "# Chanllenger = pd.read_csv('Dataset/lose_10/10_Chanllenger.csv')\n",
    "# Chanllenger_ver2 = pd.read_csv('Dataset/win_10/10_Chanllenger_ver2.csv')\n",
    "# Chanllenger_ver2 = pd.read_csv('Dataset/lose_10/10_Chanllenger_ver2.csv')\n",
    "# win_10_Grandmaster = pd.read_csv('Dataset/win_10/win_10_Grandmaster.csv')\n",
    "# lose_10_Grandmaster = pd.read_csv('Dataset/lose_10/lose_10_Grandmaster.csv')\n",
    "\n",
    "win_Chanllenger = pd.read_csv('Dataset/win/Chanllenger.csv')\n",
    "lose_Chanllenger = pd.read_csv('Dataset/lose/Chanllenger.csv')\n",
    "Chanllenger = pd.concat([win_Chanllenger, lose_Chanllenger], ignore_index=True)\n",
    "print(Chanllenger['result'].value_counts())\n",
    "\n",
    "win_Grandmaster = pd.read_csv('Dataset/win/Grandmaster.csv')\n",
    "lose_Grandmaster = pd.read_csv('Dataset/lose/Grandmaster.csv')\n",
    "Grandmaster = pd.concat([win_Grandmaster, lose_Grandmaster], ignore_index=True)\n",
    "print(Grandmaster['result'].value_counts())\n",
    "\n",
    "win_Master = pd.read_csv('Dataset/win/Master.csv')\n",
    "lose_Master = pd.read_csv('Dataset/lose/Master.csv')\n",
    "Master = pd.concat([win_Master, lose_Master], ignore_index=True)\n",
    "print(Master['result'].value_counts())\n",
    "\n",
    "win_Emerald_I = pd.read_csv('Dataset/win/Emerald_I.csv')\n",
    "lose_Emerald_I = pd.read_csv('Dataset/lose/Emerald_I.csv')\n",
    "win_Emerald_II = pd.read_csv('Dataset/win/Emerald_II.csv')\n",
    "lose_Emerald_II = pd.read_csv('Dataset/lose/Emerald_II.csv')\n",
    "win_Emerald_III = pd.read_csv('Dataset/win/Emerald_III.csv')\n",
    "lose_Emerald_III = pd.read_csv('Dataset/lose/Emerald_III.csv')\n",
    "win_Emerald_IV = pd.read_csv('Dataset/win/Emerald_IV.csv')\n",
    "lose_Emerald_IV = pd.read_csv('Dataset/lose/Emerald_IV.csv')\n",
    "Emerald = pd.concat([win_Emerald_I, win_Emerald_II, win_Emerald_III, win_Emerald_IV, lose_Emerald_I, lose_Emerald_II, lose_Emerald_III, lose_Emerald_IV], ignore_index=True)\n",
    "print(Emerald['result'].value_counts())\n",
    "\n",
    "win_Platinum_I = pd.read_csv('Dataset/win/Platinum_I.csv')\n",
    "lose_Platinum_I = pd.read_csv('Dataset/lose/Platinum_I.csv')\n",
    "win_Platinum_II = pd.read_csv('Dataset/win/Platinum_II.csv')\n",
    "lose_Platinum_II = pd.read_csv('Dataset/lose/Platinum_II.csv')\n",
    "win_Platinum_III = pd.read_csv('Dataset/win/Platinum_III.csv')\n",
    "lose_Platinum_III = pd.read_csv('Dataset/lose/Platinum_III.csv')\n",
    "win_Platinum_IV = pd.read_csv('Dataset/win/Platinum_IV.csv')\n",
    "lose_Platinum_IV = pd.read_csv('Dataset/lose/Platinum_IV.csv')\n",
    "Platinum = pd.concat([win_Platinum_I, win_Platinum_II, win_Platinum_III, win_Platinum_IV, lose_Platinum_I, lose_Platinum_II, lose_Platinum_III, lose_Platinum_IV], ignore_index=True)\n",
    "print(Platinum['result'].value_counts())\n",
    "\n",
    "win_Gold_I = pd.read_csv('Dataset/win/Gold_I.csv')\n",
    "lose_Gold_I = pd.read_csv('Dataset/lose/Gold_I.csv')\n",
    "win_Gold_II = pd.read_csv('Dataset/win/Gold_II.csv')\n",
    "lose_Gold_II = pd.read_csv('Dataset/lose/Gold_II.csv')\n",
    "win_Gold_III= pd.read_csv('Dataset/win/Gold_III.csv')\n",
    "lose_Gold_III = pd.read_csv('Dataset/lose/Gold_III.csv')\n",
    "win_Gold_IV = pd.read_csv('Dataset/win/Gold_IV.csv')\n",
    "lose_Gold_IV = pd.read_csv('Dataset/lose/Gold_IV.csv')\n",
    "Gold = pd.concat([win_Gold_I, win_Gold_II, win_Gold_III, win_Gold_IV, lose_Gold_I, lose_Gold_II, lose_Gold_III, lose_Gold_IV], ignore_index=True)\n",
    "print(Gold['result'].value_counts())\n",
    "\n",
    "\n",
    "win_Silver_I = pd.read_csv('Dataset/win/Silver_I.csv')\n",
    "lose_Silver_I = pd.read_csv('Dataset/lose/Silver_I.csv')\n",
    "win_Silver_II = pd.read_csv('Dataset/win/Silver_II.csv')\n",
    "lose_Silver_II = pd.read_csv('Dataset/lose/Silver_II.csv')\n",
    "win_Silver_III = pd.read_csv('Dataset/win/Silver_III.csv')\n",
    "lose_Silver_III = pd.read_csv('Dataset/lose/Silver_III.csv')\n",
    "win_Silver_IV = pd.read_csv('Dataset/win/Silver_IV.csv')\n",
    "lose_Silver_IV = pd.read_csv('Dataset/lose/Silver_IV.csv')\n",
    "Silver = pd.concat([win_Silver_I, win_Silver_II, win_Silver_III, win_Silver_IV, lose_Silver_I, lose_Silver_II, lose_Silver_III, lose_Silver_IV], ignore_index=True)\n",
    "print(Silver['result'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "data2 = pd.concat([win_Chanllenger_ver2, lose_Chanllenger_ver2], ignore_index=True)\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "# data = pd.concat([win_10_Chanllenger, lose_10_Chanllenger], ignore_index=True)\n",
    "# data = pd.concat([win_Silver, lose_Silver], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 무의미한 변수 제거\n",
    "data= data.drop(['matchId'],axis=1)\n",
    "data= data.drop(['queueId'],axis=1)\n",
    "data= data.drop(['K-WIN-top'],axis=1)\n",
    "data= data.drop(['K-LOSE-top'],axis=1)\n",
    "data= data.drop(['K-WIN-jug'],axis=1)\n",
    "data= data.drop(['K-LOSE-jug'],axis=1)\n",
    "data= data.drop(['K-WIN-mid'],axis=1)\n",
    "data= data.drop(['K-LOSE-mid'],axis=1)\n",
    "data= data.drop(['K-WIN-ad'],axis=1)\n",
    "data= data.drop(['K-LOSE-ad'],axis=1)\n",
    "data= data.drop(['K-WIN-sup'],axis=1)\n",
    "data= data.drop(['K-LOSE-sup'],axis=1)\n",
    "data= data.drop(['LOSE_controlWARDPlaced'],axis=1)\n",
    "data= data.drop(['WIN_controlWARDPlaced'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :21]\n",
    "y = data.iloc[:, 21:]\n",
    "\n",
    "# # features/target, train/test dataset 분리\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest : 86.97 %\n",
      "RandomForest f1 : 87.05 %\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state = 10)\n",
    "rf.fit(train_x,train_y)\n",
    "rf_pre = rf.predict(test_x)\n",
    "print(\"RandomForest :\", round(accuracy_score(test_y, rf_pre)*100, 2), \"%\")\n",
    "print(\"RandomForest f1 :\", round(f1_score(test_y, rf_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3376, number of negative: 3394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 6770, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498671 -> initscore=-0.005318\n",
      "[LightGBM] [Info] Start training from score -0.005318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM : 87.32 %\n",
      "lightGBM f1 : 87.53 %\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=100)\n",
    "lgbm.fit(train_x, train_y)\n",
    "lgbm_pre = lgbm.predict(test_x)\n",
    "print(\"lightGBM :\", round(accuracy_score(test_y, lgbm_pre)*100, 2), \"%\")\n",
    "print(\"lightGBM f1 :\", round(f1_score(test_y, lgbm_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4409085\ttotal: 11.5ms\tremaining: 11.5ms\n",
      "1:\tlearn: 0.4248691\ttotal: 14.2ms\tremaining: 0us\n",
      "CatBoost : 82.77 %\n",
      "CatBoost f1 : 82.37 %\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=2, depth=2, learning_rate=1)\n",
    "cat.fit(train_x, train_y)\n",
    "cat_pre = cat.predict(test_x)\n",
    "print(\"CatBoost :\", round(accuracy_score(test_y, cat_pre)*100, 2), \"%\")\n",
    "print(\"CatBoost f1 :\", round(f1_score(test_y, cat_pre)*100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees : 83.39 %\n",
      "ExtraTrees f1 : 83.5 %\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "et.fit(train_x, train_y)\n",
    "et_pre = et.predict(test_x)\n",
    "print(\"ExtraTrees :\", round(accuracy_score(test_y, et_pre)*100, 2), \"%\")\n",
    "print(\"ExtraTrees f1 :\", round(f1_score(test_y, et_pre)*100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
