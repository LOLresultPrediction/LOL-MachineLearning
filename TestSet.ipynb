{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_win_dataframe_to_csv(dataframe, filename):\n",
    "    df = pd.DataFrame(dataframe)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lose_dataframe_to_csv(dataframe, filename):\n",
    "    df = pd.DataFrame(dataframe)\n",
    "    columns_to_exclude_index = [0, 1, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 26, 34]  \n",
    "    columns_to_multiply_by_minus_1_index = [col_idx for col_idx in range(len(df.columns)) if col_idx not in columns_to_exclude_index]\n",
    "    df.iloc[:, columns_to_multiply_by_minus_1_index] = df.iloc[:, columns_to_multiply_by_minus_1_index] * -1\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"Dataset/win/Platinum_I.csv\")\n",
    "data2 = pd.read_csv(\"Dataset/win/Platinum_II.csv\")\n",
    "data3 = pd.read_csv(\"Dataset/win/Platinum_III.csv\")\n",
    "data4 = pd.read_csv(\"Dataset/win/Platinum_IV.csv\")\n",
    "\n",
    "#티어별로 2500개씩 슬라이싱\n",
    "data1 = data1.drop(data1.index[2500:])\n",
    "data2 = data2.drop(data2.index[2500:])\n",
    "data3 = data3.drop(data3.index[2500:])\n",
    "data4 = data4.drop(data4.index[2500:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            matchId  queueId  Diff_LV  Diff_CS  Diff_jglCS  Diff-K  \\\n",
      "0     KR_6728675184      420       -3      -12         -10     -10   \n",
      "1     KR_6755780484      440        4       81          28       9   \n",
      "2     KR_6768062927      440       -3       24         -23      -4   \n",
      "3     KR_6759156095      420        1       67          12       5   \n",
      "4     KR_6605744824      440        1      -12         -28       8   \n",
      "...             ...      ...      ...      ...         ...     ...   \n",
      "2496  KR_6530673429      420       -1       22         -20      -7   \n",
      "2497  KR_6683153161      420        1       21          21      -9   \n",
      "2498  KR_6764933526      420        1       60          32      11   \n",
      "2499  KR_6758172560      420       -2        7         -34       6   \n",
      "2500  KR_6726879839      420       -1      -23          -7      -4   \n",
      "\n",
      "      Diff-K-top  K-WIN-top  K-LOSE-top  Diff-K-jug  ...  \\\n",
      "0              1          3           2          -3  ...   \n",
      "1              1          1           0           4  ...   \n",
      "2              5          5           0           0  ...   \n",
      "3              2          3           1           7  ...   \n",
      "4             10         10           0           2  ...   \n",
      "...          ...        ...         ...         ...  ...   \n",
      "2496           4          4           0          -2  ...   \n",
      "2497          -2          0           2           4  ...   \n",
      "2498          -6          2           8          -2  ...   \n",
      "2499           4          4           0           0  ...   \n",
      "2500           0          4           4          -4  ...   \n",
      "\n",
      "      WIN_controlWARDPlaced  Diff_WARDkill  Diff_Inhibitor  Diff_TOWERkill  \\\n",
      "0                         7             -7               0              -1   \n",
      "1                         7              0               0               3   \n",
      "2                         4              0               0              -2   \n",
      "3                         4              9               0              -1   \n",
      "4                         4             -4               0              -1   \n",
      "...                     ...            ...             ...             ...   \n",
      "2496                      2             -6               0               1   \n",
      "2497                      9             -1               0               0   \n",
      "2498                      2              1               0               3   \n",
      "2499                      5             -1               0               1   \n",
      "2500                      8              1               0               1   \n",
      "\n",
      "      Diff_FirstDRAGON  Diff_FirstHERALD  Diff_Firsttower  Diff_FirstBLOOD  \\\n",
      "0                   -1                 1                1               -1   \n",
      "1                   -1                -1                1               -1   \n",
      "2                    0                -1               -1                1   \n",
      "3                   -1                 1               -1               -1   \n",
      "4                   -1                -1               -1               -1   \n",
      "...                ...               ...              ...              ...   \n",
      "2496                -1                 1                1                1   \n",
      "2497                 1                -1                0               -1   \n",
      "2498                 0                 1                1                1   \n",
      "2499                 1                -1                1                1   \n",
      "2500                -1                 1                1                1   \n",
      "\n",
      "      dragonType  result  \n",
      "0              4       1  \n",
      "1              6       1  \n",
      "2              0       1  \n",
      "3              5       1  \n",
      "4              3       1  \n",
      "...          ...     ...  \n",
      "2496           2       1  \n",
      "2497           1       1  \n",
      "2498           0       1  \n",
      "2499           4       1  \n",
      "2500           2       1  \n",
      "\n",
      "[2501 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "windata = pd.concat([data1,data2,data3,data4])\n",
    "windata = windata.drop_duplicates(subset=['matchId'], keep='first')  # 또는 keep='last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_win_dataframe_to_csv(windata,\"Dataset/win/Platinum_win.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_lose_dataframe_to_csv(windata,\"Dataset/lose/Gold_lose_concat_finalsss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "losedata = pd.read_csv(\"Dataset/lose/Gold_lose_concat_finalsss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: matchId, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "compare = losedata[losedata['matchId'].duplicated(keep=False)]\n",
    "print(compare['matchId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat([windata, losedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(data['Diff-A'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Diff-A'] = data['Diff-A']*-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [ 1. nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\TeamLOL\\LOL-MachineLearning\\TestSet.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/TeamLOL/LOL-MachineLearning/TestSet.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#df[features]을 통해 특정 칼럼들로 학습 데이터로 사용한다. 그리고 df['result'] 이 부분을 통해 각 게임에 대한 승패 결과를 교육(?)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/TeamLOL/LOL-MachineLearning/TestSet.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model \u001b[39m=\u001b[39m XGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\u001b[39m#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/TeamLOL/LOL-MachineLearning/TestSet.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/TeamLOL/LOL-MachineLearning/TestSet.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/TeamLOL/LOL-MachineLearning/TestSet.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\proce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\proce\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1467\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     expected_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1463\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1464\u001b[0m     classes\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1465\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (classes \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1466\u001b[0m ):\n\u001b[1;32m-> 1467\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1468\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1469\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mclasses\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1470\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [ 1. nan]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# df = pd.read_csv('Grandmaster_concat.csv')\n",
    "\n",
    "\n",
    "#data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "#df[features]을 통해 특정 칼럼들로 학습 데이터로 사용한다. 그리고 df['result'] 이 부분을 통해 각 게임에 대한 승패 결과를 교육(?)\n",
    "model = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=12, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9151076597246735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = RandomForestClassifier(n_estimators=120, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "2647   -1\n",
      "2648   -1\n",
      "2649   -1\n",
      "2650   -1\n",
      "2651   -1\n",
      "Name: result, Length: 13167, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(windata[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9888, number of negative: 9862\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 19750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500658 -> initscore=0.002633\n",
      "[LightGBM] [Info] Start training from score 0.002633\n",
      "정확도: 0.7777946537059538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = LGBMClassifier(n_estimators=400)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.285308\n",
      "0:\tlearn: 0.5164657\ttotal: 154ms\tremaining: 15.3s\n",
      "1:\tlearn: 0.3980603\ttotal: 163ms\tremaining: 8s\n",
      "2:\tlearn: 0.3419642\ttotal: 172ms\tremaining: 5.57s\n",
      "3:\tlearn: 0.3175816\ttotal: 182ms\tremaining: 4.37s\n",
      "4:\tlearn: 0.2918697\ttotal: 191ms\tremaining: 3.63s\n",
      "5:\tlearn: 0.2765550\ttotal: 203ms\tremaining: 3.18s\n",
      "6:\tlearn: 0.2672256\ttotal: 214ms\tremaining: 2.84s\n",
      "7:\tlearn: 0.2534970\ttotal: 223ms\tremaining: 2.56s\n",
      "8:\tlearn: 0.2437030\ttotal: 234ms\tremaining: 2.37s\n",
      "9:\tlearn: 0.2411426\ttotal: 244ms\tremaining: 2.19s\n",
      "10:\tlearn: 0.2288217\ttotal: 253ms\tremaining: 2.05s\n",
      "11:\tlearn: 0.2215912\ttotal: 263ms\tremaining: 1.93s\n",
      "12:\tlearn: 0.2114128\ttotal: 272ms\tremaining: 1.82s\n",
      "13:\tlearn: 0.2058374\ttotal: 282ms\tremaining: 1.73s\n",
      "14:\tlearn: 0.1977432\ttotal: 293ms\tremaining: 1.66s\n",
      "15:\tlearn: 0.1950502\ttotal: 303ms\tremaining: 1.59s\n",
      "16:\tlearn: 0.1881008\ttotal: 315ms\tremaining: 1.54s\n",
      "17:\tlearn: 0.1854144\ttotal: 325ms\tremaining: 1.48s\n",
      "18:\tlearn: 0.1795411\ttotal: 335ms\tremaining: 1.43s\n",
      "19:\tlearn: 0.1771174\ttotal: 346ms\tremaining: 1.38s\n",
      "20:\tlearn: 0.1751132\ttotal: 357ms\tremaining: 1.34s\n",
      "21:\tlearn: 0.1664824\ttotal: 369ms\tremaining: 1.31s\n",
      "22:\tlearn: 0.1635601\ttotal: 381ms\tremaining: 1.27s\n",
      "23:\tlearn: 0.1631352\ttotal: 391ms\tremaining: 1.24s\n",
      "24:\tlearn: 0.1595712\ttotal: 402ms\tremaining: 1.21s\n",
      "25:\tlearn: 0.1538146\ttotal: 414ms\tremaining: 1.18s\n",
      "26:\tlearn: 0.1491315\ttotal: 425ms\tremaining: 1.15s\n",
      "27:\tlearn: 0.1481347\ttotal: 442ms\tremaining: 1.14s\n",
      "28:\tlearn: 0.1456910\ttotal: 457ms\tremaining: 1.12s\n",
      "29:\tlearn: 0.1412775\ttotal: 469ms\tremaining: 1.09s\n",
      "30:\tlearn: 0.1397315\ttotal: 482ms\tremaining: 1.07s\n",
      "31:\tlearn: 0.1377786\ttotal: 496ms\tremaining: 1.05s\n",
      "32:\tlearn: 0.1336267\ttotal: 510ms\tremaining: 1.03s\n",
      "33:\tlearn: 0.1293870\ttotal: 522ms\tremaining: 1.01s\n",
      "34:\tlearn: 0.1283044\ttotal: 533ms\tremaining: 990ms\n",
      "35:\tlearn: 0.1251892\ttotal: 546ms\tremaining: 970ms\n",
      "36:\tlearn: 0.1250962\ttotal: 558ms\tremaining: 950ms\n",
      "37:\tlearn: 0.1221356\ttotal: 571ms\tremaining: 931ms\n",
      "38:\tlearn: 0.1205409\ttotal: 583ms\tremaining: 912ms\n",
      "39:\tlearn: 0.1190957\ttotal: 597ms\tremaining: 895ms\n",
      "40:\tlearn: 0.1190767\ttotal: 611ms\tremaining: 879ms\n",
      "41:\tlearn: 0.1166136\ttotal: 628ms\tremaining: 867ms\n",
      "42:\tlearn: 0.1165537\ttotal: 641ms\tremaining: 849ms\n",
      "43:\tlearn: 0.1161720\ttotal: 657ms\tremaining: 836ms\n",
      "44:\tlearn: 0.1152652\ttotal: 669ms\tremaining: 817ms\n",
      "45:\tlearn: 0.1143090\ttotal: 680ms\tremaining: 799ms\n",
      "46:\tlearn: 0.1116979\ttotal: 694ms\tremaining: 782ms\n",
      "47:\tlearn: 0.1092820\ttotal: 709ms\tremaining: 768ms\n",
      "48:\tlearn: 0.1070658\ttotal: 722ms\tremaining: 752ms\n",
      "49:\tlearn: 0.1047291\ttotal: 735ms\tremaining: 735ms\n",
      "50:\tlearn: 0.1024993\ttotal: 747ms\tremaining: 718ms\n",
      "51:\tlearn: 0.1007483\ttotal: 764ms\tremaining: 705ms\n",
      "52:\tlearn: 0.0996989\ttotal: 777ms\tremaining: 689ms\n",
      "53:\tlearn: 0.0980054\ttotal: 788ms\tremaining: 671ms\n",
      "54:\tlearn: 0.0962588\ttotal: 801ms\tremaining: 655ms\n",
      "55:\tlearn: 0.0952304\ttotal: 813ms\tremaining: 639ms\n",
      "56:\tlearn: 0.0943764\ttotal: 827ms\tremaining: 624ms\n",
      "57:\tlearn: 0.0932004\ttotal: 840ms\tremaining: 608ms\n",
      "58:\tlearn: 0.0919122\ttotal: 852ms\tremaining: 592ms\n",
      "59:\tlearn: 0.0906188\ttotal: 870ms\tremaining: 580ms\n",
      "60:\tlearn: 0.0906139\ttotal: 882ms\tremaining: 564ms\n",
      "61:\tlearn: 0.0892721\ttotal: 905ms\tremaining: 555ms\n",
      "62:\tlearn: 0.0883284\ttotal: 921ms\tremaining: 541ms\n",
      "63:\tlearn: 0.0872775\ttotal: 933ms\tremaining: 525ms\n",
      "64:\tlearn: 0.0872412\ttotal: 943ms\tremaining: 508ms\n",
      "65:\tlearn: 0.0866513\ttotal: 957ms\tremaining: 493ms\n",
      "66:\tlearn: 0.0857589\ttotal: 969ms\tremaining: 477ms\n",
      "67:\tlearn: 0.0845030\ttotal: 980ms\tremaining: 461ms\n",
      "68:\tlearn: 0.0839394\ttotal: 993ms\tremaining: 446ms\n",
      "69:\tlearn: 0.0833834\ttotal: 1.01s\tremaining: 432ms\n",
      "70:\tlearn: 0.0821926\ttotal: 1.02s\tremaining: 418ms\n",
      "71:\tlearn: 0.0813432\ttotal: 1.04s\tremaining: 404ms\n",
      "72:\tlearn: 0.0802557\ttotal: 1.05s\tremaining: 391ms\n",
      "73:\tlearn: 0.0798392\ttotal: 1.08s\tremaining: 379ms\n",
      "74:\tlearn: 0.0791171\ttotal: 1.1s\tremaining: 366ms\n",
      "75:\tlearn: 0.0780407\ttotal: 1.11s\tremaining: 352ms\n",
      "76:\tlearn: 0.0774235\ttotal: 1.13s\tremaining: 338ms\n",
      "77:\tlearn: 0.0766793\ttotal: 1.15s\tremaining: 325ms\n",
      "78:\tlearn: 0.0761083\ttotal: 1.17s\tremaining: 310ms\n",
      "79:\tlearn: 0.0761005\ttotal: 1.18s\tremaining: 296ms\n",
      "80:\tlearn: 0.0758902\ttotal: 1.2s\tremaining: 282ms\n",
      "81:\tlearn: 0.0758630\ttotal: 1.22s\tremaining: 267ms\n",
      "82:\tlearn: 0.0753123\ttotal: 1.23s\tremaining: 253ms\n",
      "83:\tlearn: 0.0746137\ttotal: 1.25s\tremaining: 238ms\n",
      "84:\tlearn: 0.0745061\ttotal: 1.26s\tremaining: 223ms\n",
      "85:\tlearn: 0.0737081\ttotal: 1.28s\tremaining: 208ms\n",
      "86:\tlearn: 0.0736207\ttotal: 1.37s\tremaining: 205ms\n",
      "87:\tlearn: 0.0730798\ttotal: 1.4s\tremaining: 191ms\n",
      "88:\tlearn: 0.0719706\ttotal: 1.41s\tremaining: 175ms\n",
      "89:\tlearn: 0.0714579\ttotal: 1.43s\tremaining: 159ms\n",
      "90:\tlearn: 0.0710234\ttotal: 1.44s\tremaining: 143ms\n",
      "91:\tlearn: 0.0703286\ttotal: 1.46s\tremaining: 127ms\n",
      "92:\tlearn: 0.0701239\ttotal: 1.47s\tremaining: 110ms\n",
      "93:\tlearn: 0.0695693\ttotal: 1.48s\tremaining: 94.4ms\n",
      "94:\tlearn: 0.0686210\ttotal: 1.49s\tremaining: 78.6ms\n",
      "95:\tlearn: 0.0686150\ttotal: 1.5s\tremaining: 62.7ms\n",
      "96:\tlearn: 0.0682612\ttotal: 1.52s\tremaining: 47ms\n",
      "97:\tlearn: 0.0675413\ttotal: 1.53s\tremaining: 31.3ms\n",
      "98:\tlearn: 0.0670128\ttotal: 1.54s\tremaining: 15.6ms\n",
      "99:\tlearn: 0.0662311\ttotal: 1.56s\tremaining: 0us\n",
      "정확도: 0.9645252382633251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = CatBoostClassifier(iterations=100, random_state=123)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7952612393681653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
