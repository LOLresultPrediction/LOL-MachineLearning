{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(dataframe, filename):\n",
    "    df = pd.DataFrame(dataframe)\n",
    "    columns_to_exclude_index = [0, 1, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 26, 34]  \n",
    "    columns_to_multiply_by_minus_1_index = [col_idx for col_idx in range(len(df.columns)) if col_idx not in columns_to_exclude_index]\n",
    "    df.iloc[:, columns_to_multiply_by_minus_1_index] = df.iloc[:, columns_to_multiply_by_minus_1_index] * -1\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"Dataset/win/Silver_I.csv\")\n",
    "data2 = pd.read_csv(\"Dataset/win/Silver_II.csv\")\n",
    "data3 = pd.read_csv(\"Dataset/win/Silver_III.csv\")\n",
    "data4 = pd.read_csv(\"Dataset/win/Silver_IV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "windata = pd.concat([data1,data2,data3,data4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe_to_csv(windata,\"Dataset/lose/Gold_lose_concats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = pd.read_csv(\"Dataset/lose/Silver_I_lose.csv\")\n",
    "data6 = pd.read_csv(\"Dataset/lose/Silver_II_lose.csv\")\n",
    "data7 = pd.read_csv(\"Dataset/lose/Silver_III_lose.csv\")\n",
    "data8 = pd.read_csv(\"Dataset/lose/Silver_IV_lose.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "losedata = pd.read_csv(\"Dataset/lose/Silver_lose_concat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "losedata = pd.concat([data5,data6,data7,data8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat([windata, losedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2714   -1\n",
      "2715   -1\n",
      "2716   -1\n",
      "2717   -1\n",
      "2718   -1\n",
      "Name: result, Length: 22664, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7911603888213852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# df = pd.read_csv('Grandmaster_concat.csv')\n",
    "\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "#df[features]을 통해 특정 칼럼들로 학습 데이터로 사용한다. 그리고 df['result'] 이 부분을 통해 각 게임에 대한 승패 결과를 교육(?)\n",
    "model = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=12, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7998177399756987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = RandomForestClassifier(n_estimators=120, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9888, number of negative: 9862\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 19750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500658 -> initscore=0.002633\n",
      "[LightGBM] [Info] Start training from score 0.002633\n",
      "정확도: 0.7777946537059538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = LGBMClassifier(n_estimators=400)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.304187\n",
      "0:\tlearn: 0.5908507\ttotal: 150ms\tremaining: 14.8s\n",
      "1:\tlearn: 0.5376222\ttotal: 162ms\tremaining: 7.92s\n",
      "2:\tlearn: 0.5094473\ttotal: 173ms\tremaining: 5.58s\n",
      "3:\tlearn: 0.4970889\ttotal: 186ms\tremaining: 4.45s\n",
      "4:\tlearn: 0.4881441\ttotal: 200ms\tremaining: 3.8s\n",
      "5:\tlearn: 0.4821653\ttotal: 211ms\tremaining: 3.31s\n",
      "6:\tlearn: 0.4783542\ttotal: 223ms\tremaining: 2.96s\n",
      "7:\tlearn: 0.4758225\ttotal: 237ms\tremaining: 2.73s\n",
      "8:\tlearn: 0.4744318\ttotal: 248ms\tremaining: 2.5s\n",
      "9:\tlearn: 0.4731509\ttotal: 258ms\tremaining: 2.32s\n",
      "10:\tlearn: 0.4713946\ttotal: 272ms\tremaining: 2.2s\n",
      "11:\tlearn: 0.4705387\ttotal: 286ms\tremaining: 2.1s\n",
      "12:\tlearn: 0.4693619\ttotal: 298ms\tremaining: 1.99s\n",
      "13:\tlearn: 0.4682308\ttotal: 311ms\tremaining: 1.91s\n",
      "14:\tlearn: 0.4671658\ttotal: 321ms\tremaining: 1.82s\n",
      "15:\tlearn: 0.4658264\ttotal: 332ms\tremaining: 1.74s\n",
      "16:\tlearn: 0.4644178\ttotal: 342ms\tremaining: 1.67s\n",
      "17:\tlearn: 0.4632631\ttotal: 353ms\tremaining: 1.61s\n",
      "18:\tlearn: 0.4620082\ttotal: 364ms\tremaining: 1.55s\n",
      "19:\tlearn: 0.4614994\ttotal: 375ms\tremaining: 1.5s\n",
      "20:\tlearn: 0.4607993\ttotal: 388ms\tremaining: 1.46s\n",
      "21:\tlearn: 0.4600645\ttotal: 401ms\tremaining: 1.42s\n",
      "22:\tlearn: 0.4587752\ttotal: 413ms\tremaining: 1.38s\n",
      "23:\tlearn: 0.4583687\ttotal: 426ms\tremaining: 1.35s\n",
      "24:\tlearn: 0.4576256\ttotal: 442ms\tremaining: 1.32s\n",
      "25:\tlearn: 0.4572002\ttotal: 455ms\tremaining: 1.29s\n",
      "26:\tlearn: 0.4568822\ttotal: 468ms\tremaining: 1.26s\n",
      "27:\tlearn: 0.4565520\ttotal: 480ms\tremaining: 1.24s\n",
      "28:\tlearn: 0.4560192\ttotal: 492ms\tremaining: 1.21s\n",
      "29:\tlearn: 0.4553690\ttotal: 504ms\tremaining: 1.18s\n",
      "30:\tlearn: 0.4546984\ttotal: 516ms\tremaining: 1.15s\n",
      "31:\tlearn: 0.4537987\ttotal: 531ms\tremaining: 1.13s\n",
      "32:\tlearn: 0.4524638\ttotal: 550ms\tremaining: 1.12s\n",
      "33:\tlearn: 0.4515401\ttotal: 577ms\tremaining: 1.12s\n",
      "34:\tlearn: 0.4507838\ttotal: 595ms\tremaining: 1.1s\n",
      "35:\tlearn: 0.4497052\ttotal: 615ms\tremaining: 1.09s\n",
      "36:\tlearn: 0.4488573\ttotal: 629ms\tremaining: 1.07s\n",
      "37:\tlearn: 0.4488109\ttotal: 642ms\tremaining: 1.05s\n",
      "38:\tlearn: 0.4484348\ttotal: 659ms\tremaining: 1.03s\n",
      "39:\tlearn: 0.4474639\ttotal: 678ms\tremaining: 1.02s\n",
      "40:\tlearn: 0.4463849\ttotal: 693ms\tremaining: 998ms\n",
      "41:\tlearn: 0.4457606\ttotal: 708ms\tremaining: 978ms\n",
      "42:\tlearn: 0.4456688\ttotal: 721ms\tremaining: 956ms\n",
      "43:\tlearn: 0.4453388\ttotal: 734ms\tremaining: 934ms\n",
      "44:\tlearn: 0.4446979\ttotal: 746ms\tremaining: 912ms\n",
      "45:\tlearn: 0.4435799\ttotal: 761ms\tremaining: 893ms\n",
      "46:\tlearn: 0.4421990\ttotal: 774ms\tremaining: 873ms\n",
      "47:\tlearn: 0.4416758\ttotal: 787ms\tremaining: 853ms\n",
      "48:\tlearn: 0.4405936\ttotal: 801ms\tremaining: 833ms\n",
      "49:\tlearn: 0.4395844\ttotal: 817ms\tremaining: 817ms\n",
      "50:\tlearn: 0.4388088\ttotal: 829ms\tremaining: 797ms\n",
      "51:\tlearn: 0.4376091\ttotal: 857ms\tremaining: 791ms\n",
      "52:\tlearn: 0.4370956\ttotal: 872ms\tremaining: 774ms\n",
      "53:\tlearn: 0.4370575\ttotal: 886ms\tremaining: 755ms\n",
      "54:\tlearn: 0.4365290\ttotal: 902ms\tremaining: 738ms\n",
      "55:\tlearn: 0.4355567\ttotal: 917ms\tremaining: 720ms\n",
      "56:\tlearn: 0.4352402\ttotal: 930ms\tremaining: 702ms\n",
      "57:\tlearn: 0.4343606\ttotal: 946ms\tremaining: 685ms\n",
      "58:\tlearn: 0.4333073\ttotal: 962ms\tremaining: 668ms\n",
      "59:\tlearn: 0.4323444\ttotal: 975ms\tremaining: 650ms\n",
      "60:\tlearn: 0.4316462\ttotal: 990ms\tremaining: 633ms\n",
      "61:\tlearn: 0.4316119\ttotal: 1s\tremaining: 615ms\n",
      "62:\tlearn: 0.4312105\ttotal: 1.02s\tremaining: 597ms\n",
      "63:\tlearn: 0.4303552\ttotal: 1.03s\tremaining: 579ms\n",
      "64:\tlearn: 0.4296230\ttotal: 1.04s\tremaining: 563ms\n",
      "65:\tlearn: 0.4283983\ttotal: 1.06s\tremaining: 547ms\n",
      "66:\tlearn: 0.4274453\ttotal: 1.08s\tremaining: 533ms\n",
      "67:\tlearn: 0.4266914\ttotal: 1.1s\tremaining: 517ms\n",
      "68:\tlearn: 0.4258413\ttotal: 1.11s\tremaining: 500ms\n",
      "69:\tlearn: 0.4245896\ttotal: 1.13s\tremaining: 483ms\n",
      "70:\tlearn: 0.4237601\ttotal: 1.14s\tremaining: 467ms\n",
      "71:\tlearn: 0.4230154\ttotal: 1.16s\tremaining: 450ms\n",
      "72:\tlearn: 0.4224678\ttotal: 1.17s\tremaining: 434ms\n",
      "73:\tlearn: 0.4219942\ttotal: 1.19s\tremaining: 418ms\n",
      "74:\tlearn: 0.4214549\ttotal: 1.2s\tremaining: 402ms\n",
      "75:\tlearn: 0.4207169\ttotal: 1.23s\tremaining: 389ms\n",
      "76:\tlearn: 0.4200299\ttotal: 1.25s\tremaining: 373ms\n",
      "77:\tlearn: 0.4191217\ttotal: 1.27s\tremaining: 357ms\n",
      "78:\tlearn: 0.4186434\ttotal: 1.32s\tremaining: 352ms\n",
      "79:\tlearn: 0.4179920\ttotal: 1.35s\tremaining: 338ms\n",
      "80:\tlearn: 0.4173179\ttotal: 1.38s\tremaining: 323ms\n",
      "81:\tlearn: 0.4163193\ttotal: 1.4s\tremaining: 306ms\n",
      "82:\tlearn: 0.4155567\ttotal: 1.41s\tremaining: 289ms\n",
      "83:\tlearn: 0.4139974\ttotal: 1.42s\tremaining: 271ms\n",
      "84:\tlearn: 0.4129619\ttotal: 1.44s\tremaining: 253ms\n",
      "85:\tlearn: 0.4122528\ttotal: 1.45s\tremaining: 236ms\n",
      "86:\tlearn: 0.4117015\ttotal: 1.46s\tremaining: 218ms\n",
      "87:\tlearn: 0.4116604\ttotal: 1.47s\tremaining: 201ms\n",
      "88:\tlearn: 0.4112732\ttotal: 1.49s\tremaining: 184ms\n",
      "89:\tlearn: 0.4104233\ttotal: 1.5s\tremaining: 167ms\n",
      "90:\tlearn: 0.4091143\ttotal: 1.51s\tremaining: 150ms\n",
      "91:\tlearn: 0.4086402\ttotal: 1.53s\tremaining: 133ms\n",
      "92:\tlearn: 0.4080044\ttotal: 1.54s\tremaining: 116ms\n",
      "93:\tlearn: 0.4075086\ttotal: 1.55s\tremaining: 99.1ms\n",
      "94:\tlearn: 0.4067058\ttotal: 1.56s\tremaining: 82.4ms\n",
      "95:\tlearn: 0.4058430\ttotal: 1.58s\tremaining: 65.7ms\n",
      "96:\tlearn: 0.4049059\ttotal: 1.59s\tremaining: 49.2ms\n",
      "97:\tlearn: 0.4034589\ttotal: 1.6s\tremaining: 32.8ms\n",
      "98:\tlearn: 0.4024888\ttotal: 1.62s\tremaining: 16.4ms\n",
      "99:\tlearn: 0.4015853\ttotal: 1.63s\tremaining: 0us\n",
      "정확도: 0.7685297691373025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = CatBoostClassifier(iterations=100, random_state=123)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7952612393681653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data['result'] = data['result'].replace({-1: 0})\n",
    "\n",
    "\n",
    "features = ['Diff_LV', 'Diff_CS', 'Diff_jglCS', 'Diff-K', 'Diff-K-top', 'Diff-K-jug', 'Diff-K-mid', 'Diff-K-ad',\n",
    "            'Diff-K-sup', 'invadeKill', 'Diff-A', 'Diff_WARDplaced', 'Diff-ControlWARDplaced', 'Diff_WARDkill',\n",
    "            'Diff_Inhibitor', 'Diff_TOWERkill', 'Diff_FirstDRAGON', 'Diff_FirstHERALD', 'Diff_Firsttower', 'Diff_FirstBLOOD']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['result'], test_size=0.25, random_state=32)\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=32)#n_estimators는 의사 결정 트리의 수. 값을 높게 설정 할 수록 정확도가 좋다고 한다.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
